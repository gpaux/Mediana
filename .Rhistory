power = sapply(prob, function(x) getPowerOneSampleProp(40,x))
plot(power)
plot(power, xaxis = prob)
plot(power, x.axis = prob)
?plot
plot(power, xlab = prob)
plot(power, x.axis = prob)
power
prob
which(prob == 0.3)
which(prob == 0.7)
which(prob == 1)
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
lapply(as.list(n), function(x) {
rep = rbinom(10000,x,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
}
power = sapply(prob, function(x) getPowerOneSampleProp(40,x))
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
power = lapply(as.list(n), function(x) {
rep = rbinom(10000,x,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
return(power)
}
power = sapply(prob, function(x) getPowerOneSampleProp(40,x))
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
power = lapply(as.list(n), function(x) {
rep = rbinom(10000,x,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
})
return(power)
}
power = sapply(prob, function(x) getPowerOneSampleProp(40,x))
length(power)
power[[1]]
?power
??power
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,x,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,x,p)
pval = sapply(rep, function(y) {
return(binom.test(x=n, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=n, n=x, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
?binom.test
prob = seq(0,1,0.05)
n = seq(40,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
plot(power[[1]])
power[[1]]
power[[2]]
power[[3]]
power = as.data.frame(power)
power
# Simple design, two arm, rando 1:1, no futility
prob = seq(0,1,0.05)
n = seq(30,40,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
power.df = unlist(power)
power.df
rep(n,length(prob))
?rep
power = lapply(as.list(n), function(y) {sapply(prob, function(x) data.frame(power = getPowerOneSampleProp(y,x), n = y)})
power = lapply(as.list(n), function(y) {sapply(prob, function(x) data.frame(power = getPowerOneSampleProp(y,x), n = y))})
?do.call
power
power.df = do.call(rbind, power)
power.df
power.df = do.call(cbind, power)
power.df
p=0.70
p0=0.60
alpha=0.025
z=(p-p0)/sqrt(p0*(1-p0)/n)
(Power=pnorm(sqrt(p0*(1-p0)/p/(1-p))*(abs(z)-qnorm(1-alpha))))
z
power
n
n = seq(30,60,10)
p=0.70
p0=0.60
alpha=0.025
z=(p-p0)/sqrt(p0*(1-p0)/n)
(Power=pnorm(sqrt(p0*(1-p0)/p/(1-p))*(abs(z)-qnorm(1-alpha))))
power
getPowerOneSampleProp(y,x)
x=0.7
y=50
getPowerOneSampleProp(y,x)
# Simple design, two arm, rando 1:1, no futility
prob = seq(0,1,0.05)
n = seq(30,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(10000,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) list(power = getPowerOneSampleProp(y,x), n = y))})
p
power
# Simple design, two arm, rando 1:1, no futility
prob = seq(0,1,0.05)
n = seq(30,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(100,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.6, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {sapply(prob, function(x) list(power = getPowerOneSampleProp(y,x), n = y))})
power.df = do.call(cbind, power)
plot = ggplot()
power.df
t(power)
power = lapply(as.list(n), function(y) {sapply(prob, function(x) list(power = getPowerOneSampleProp(y,x), n = y), simplify = FALSE)})
power
power.df = do.call(cbind, power)
power.df
power
power.df = do.call(unlist, power)
power.df = do.call(unlist, power)
power = lapply(as.list(n), function(y) {sapply(prob, function(x) list(power = getPowerOneSampleProp(y,x), n = y), simplify = FALSE)})
power.df = do.call(unlist, power)
power
power.df = lapply(power, unlist)
power.df
power.df = lapply(power, rbind)
power.df
power
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x), simplify = FALSE)})
power
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x)=)})
power = lapply(as.list(n), function(y) {sapply(prob, function(x) getPowerOneSampleProp(y,x))})
power
power = lapply(as.list(n), function(y) {data.frame(power = sapply(prob, function(x) getPowerOneSampleProp(y,x)), n = y)})
power
power.df = do.call(cbind, power)
power.df
power.df = do.call(rbind, power)
power.df
power = lapply(as.list(n), function(y) {data.frame(power = sapply(prob, function(x) getPowerOneSampleProp(y,x)), n = y, prob = prob)})
power.df = do.call(rbind, power)
power.df
ggplot(data = power.df, aes(x = prob, y = power, color = n)) +
geom_line()
librayr(ggplot2)
plot = ggplot(data = power.df, aes(x = prob, y = power, color = n)) +
geom_line()
librayr(ggplot2)
library(ggplot2)
ggplot(data = power.df, aes(x = prob, y = power, color = n)) +
geom_line()
plot = ggplot(data = power.df, aes(x = prob, y = power, color = as.factor(n))) +
geom_line()
plot
# Simple design, two arm, rando 1:1, no futility
prob = seq(0,1,0.05)
n = seq(30,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(100,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.5, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {data.frame(power = sapply(prob, function(x) getPowerOneSampleProp(y,x)), n = y, prob = prob)})
power.df = do.call(rbind, power)
library(ggplot2)
plot = ggplot(data = power.df, aes(x = prob, y = power, color = as.factor(n))) +
geom_line()
plot
# Simple design, two arm, rando 1:1, no futility
prob = seq(0,1,0.05)
n = seq(30,60,10)
getPowerOneSampleProp = function(n, p){
rep = rbinom(1000,n,p)
pval = sapply(rep, function(y) {
return(binom.test(x=y, n=n, p = 0.5, alternative = c("greater"), conf.level = 0.95)$p.value)
})
return(mean(pval<0.025))
}
power = lapply(as.list(n), function(y) {data.frame(power = sapply(prob, function(x) getPowerOneSampleProp(y,x)), n = y, prob = prob)})
power.df = do.call(rbind, power)
library(ggplot2)
plot = ggplot(data = power.df, aes(x = prob, y = power, color = as.factor(n))) +
geom_line()
plot
?binom.test
subset(power.df, prob == 0.7)
subset(power.df, prob >= 0.7)
# See TreeGate Manual example in section 4
# Load the function implemented in the Mediana Package
fundir = "C:/Users/GAUP_CB/Desktop/Mediana Package/R/Package_v1.0.3/Mediana-master/R"
#Include all functions in the fundir
for (nm in list.files(fundir, pattern = ".R")) {
message(paste0("Source function: ",nm))
source(file.path(fundir, nm))
}
# See TreeGate Manual example in section 4
# Load the function implemented in the Mediana Package
fundir = "C:/Users/gauti/Cloudstation/Mediana Package/R/Package_v1.0.3/Mediana-master/R"
#Include all functions in the fundir
for (nm in list.files(fundir, pattern = ".R")) {
message(paste0("Source function: ",nm))
source(file.path(fundir, nm))
}
# Number of events parameters
event.count.total = c(210, 300)
randomization.ratio = c(1,2)
# Outcome parameters
median.time.placebo = 6
rate.placebo = log(2)/median.time.placebo
outcome.placebo = parameters(rate = rate.placebo)
median.time.treatment = 9
rate.treatment = log(2)/median.time.treatment
outcome.treatment = parameters(rate = rate.treatment)
# Data model
case.study1.data.model = DataModel() +
OutcomeDist(outcome.dist = "ExpoDist") +
Event(n.events = event.count.total, rando.ratio = randomization.ratio) +
Sample(id = "Placebo",
outcome.par = parameters(outcome.placebo)) +
Sample(id = "Treatment",
outcome.par = parameters(outcome.treatment))
CreateDataStack(case.study1.data.model, n.sims = 1)
data = CreateDataStack(case.study1.data.model, n.sims = 1)
data$data.set[[1]]$data.scenario[[1]]$sample[[1]]
data = CreateDataStack(case.study1.data.model, n.sims = 1)
sample.list = list(data$data.set[[1]]$data.scenario[[1]]$sample[[1]]$data,
data$data.set[[1]]$data.scenario[[1]]$sample[[2]]$data)
sample.list
LogrankTest(sample.list, list(""))
sample.list[[1]][, "outcome"]
# Outcomes in Sample 1
outcome1 = sample.list[[1]][, "outcome"]
# Remove the missing values due to dropouts/incomplete observations
outcome1.complete = outcome1[stats::complete.cases(outcome1)]
# Observed events in Sample 1 (negation of censoring indicators)
event1 = !sample.list[[1]][, "patient.censor.indicator"]
event1.complete = event1[stats::complete.cases(outcome1)]
# Sample size in Sample 1
n1 = length(outcome1.complete)
event1.complete
event1
n1
# Outcomes in Sample 2
outcome2 = sample.list[[2]][, "outcome"]
# Remove the missing values due to dropouts/incomplete observations
outcome2.complete = outcome2[stats::complete.cases(outcome2)]
# Observed events in Sample 2 (negation of censoring indicators)
event2 = !sample.list[[2]][, "patient.censor.indicator"]
event2.complete = event2[stats::complete.cases(outcome2)]
# Sample size in Sample 2
n2 = length(outcome2.complete)
# Create combined samples of outcomes, censoring indicators (all events are observed) and treatment indicators
outcome = c(outcome1.complete, outcome2.complete)
event = c(event1.complete, event2.complete)
treatment = c(rep(0, n1), rep(1, n2))
# Apply log-rank test
surv.test = survival::survdiff(survival::Surv(outcome, event) ~ treatment)
# Compute one-sided p-value
result = stats::pchisq(surv.test$chisq, df = 1, lower.tail = FALSE)/2
# Impute the p-value to 1 if the median of the sample 2 is lower than the median in sample 1
print(surv.test$quantiles)
surv.test
str(surv.test)
quantile(surv.test)
survfit(surv.test)
library(survival)
survfit(surv.test)
survival::survdiff(survival::Surv(outcome, event) ~ treatment)
survfit(survival::Surv(outcome, event) ~ treatment)
survfit(survival::Surv(outcome, event) ~ treatment)
str(survfit(survival::Surv(outcome, event) ~ treatment))
surv.fit = survival::survfit(survival::Surv(outcome, event) ~ treatment)
result = stats::pchisq(surv.test$chisq, df = 1, lower.tail = FALSE)/2
result
print(quantile(surv.fit)$quantile[,'50'])
median = quantile(surv.test)$quantile[,'50']
median = quantile(surv.fit)$quantile[,'50']
median
median[1] > median[2]
median = as.numeric(quantile(surv.fit)$quantile[,'50'])
print(median)
median = as.numeric(quantile(surv.fit)$quantile[,'50'])
if (median[1] > median[2]) result = 1
result
######################################################################################################################
# Function: LogrankTest .
# Argument: Data set and parameter.
# Description: Computes one-sided p-value based on log-rank test.
LogrankTest = function(sample.list, parameter) {
# Determine the function call, either to generate the p-value or to return description
call = (parameter[[1]] == "Description")
if (call == FALSE | is.na(call)) {
# Sample list is assumed to include two data frames that represent two analysis samples
# Outcomes in Sample 1
outcome1 = sample.list[[1]][, "outcome"]
# Remove the missing values due to dropouts/incomplete observations
outcome1.complete = outcome1[stats::complete.cases(outcome1)]
# Observed events in Sample 1 (negation of censoring indicators)
event1 = !sample.list[[1]][, "patient.censor.indicator"]
event1.complete = event1[stats::complete.cases(outcome1)]
# Sample size in Sample 1
n1 = length(outcome1.complete)
# Outcomes in Sample 2
outcome2 = sample.list[[2]][, "outcome"]
# Remove the missing values due to dropouts/incomplete observations
outcome2.complete = outcome2[stats::complete.cases(outcome2)]
# Observed events in Sample 2 (negation of censoring indicators)
event2 = !sample.list[[2]][, "patient.censor.indicator"]
event2.complete = event2[stats::complete.cases(outcome2)]
# Sample size in Sample 2
n2 = length(outcome2.complete)
# Create combined samples of outcomes, censoring indicators (all events are observed) and treatment indicators
outcome = c(outcome1.complete, outcome2.complete)
event = c(event1.complete, event2.complete)
treatment = c(rep(0, n1), rep(1, n2))
# Apply log-rank test
surv.test = survival::survdiff(survival::Surv(outcome, event) ~ treatment)
surv.fit = survival::survfit(survival::Surv(outcome, event) ~ treatment)
# Compute one-sided p-value
result = stats::pchisq(surv.test$chisq, df = 1, lower.tail = FALSE)/2
# Impute the p-value to 1 if the median of the sample 2 is lower than the median in sample 1
median = as.numeric(quantile(surv.fit)$quantile[,'50'])
if (median[1] > median[2]) result = 1
}
else if (call == TRUE) {
result = list("Log-rank test")
}
return(result)
}
# End of LogrankTest
###################################################################
# Case study 1
# Clinical trial in patients with metastatic colorectal cancer
###################################################################
# Number of events parameters
event.count.total = c(210, 300)
randomization.ratio = c(1,2)
# Outcome parameters
median.time.placebo = 6
rate.placebo = log(2)/median.time.placebo
outcome.placebo = parameters(rate = rate.placebo)
median.time.treatment = 9
rate.treatment = log(2)/median.time.treatment
outcome.treatment = parameters(rate = rate.treatment)
# Data model
case.study1.data.model = DataModel() +
OutcomeDist(outcome.dist = "ExpoDist") +
Event(n.events = event.count.total, rando.ratio = randomization.ratio) +
Sample(id = "Placebo",
outcome.par = parameters(outcome.placebo)) +
Sample(id = "Treatment",
outcome.par = parameters(outcome.treatment))
# Analysis model
case.study1.analysis.model = AnalysisModel() +
Test(id = "Placebo vs treatment",
samples = samples("Placebo", "Treatment"),
method = "LogrankTest")
# Evaluation model
case.study1.evaluation.model = EvaluationModel() +
Criterion(id = "Marginal power",
method = "MarginalPower",
tests = tests("Placebo vs treatment"),
labels = c("Placebo vs treatment"),
par = parameters(alpha = 0.025))
# Simulation Parameters
case.study1.sim.parameters =  SimParameters(n.sims = 1000,
proc.load = "full",
seed = 42938001)
# Perform clinical scenario evaluation
case.study1.results = CSE(case.study1.data.model,
case.study1.analysis.model,
case.study1.evaluation.model,
case.study1.sim.parameters)
library(doRNG)
###################################################################
# Case study 1
# Clinical trial in patients with metastatic colorectal cancer
###################################################################
# Number of events parameters
event.count.total = c(210, 300)
randomization.ratio = c(1,2)
# Outcome parameters
median.time.placebo = 6
rate.placebo = log(2)/median.time.placebo
outcome.placebo = parameters(rate = rate.placebo)
median.time.treatment = 9
rate.treatment = log(2)/median.time.treatment
outcome.treatment = parameters(rate = rate.treatment)
# Data model
case.study1.data.model = DataModel() +
OutcomeDist(outcome.dist = "ExpoDist") +
Event(n.events = event.count.total, rando.ratio = randomization.ratio) +
Sample(id = "Placebo",
outcome.par = parameters(outcome.placebo)) +
Sample(id = "Treatment",
outcome.par = parameters(outcome.treatment))
# Analysis model
case.study1.analysis.model = AnalysisModel() +
Test(id = "Placebo vs treatment",
samples = samples("Placebo", "Treatment"),
method = "LogrankTest")
# Evaluation model
case.study1.evaluation.model = EvaluationModel() +
Criterion(id = "Marginal power",
method = "MarginalPower",
tests = tests("Placebo vs treatment"),
labels = c("Placebo vs treatment"),
par = parameters(alpha = 0.025))
# Simulation Parameters
case.study1.sim.parameters =  SimParameters(n.sims = 1000,
proc.load = "full",
seed = 42938001)
# Perform clinical scenario evaluation
case.study1.results = CSE(case.study1.data.model,
case.study1.analysis.model,
case.study1.evaluation.model,
case.study1.sim.parameters)
case.study1.results
summary(case.study1.results)
library(Mediana)
rm(list = ls())
library(Mediana)
setwd("C:/Users/gauti/CloudStation/Mediana Package/R/Package_v1.0.3/Mediana-gh-pages")
rm(list = ls())
source("Case study 1 (normally distributed endpoint).R")
rm(list = ls())
source("Case study 1 (binary endpoint).R")
rm(list = ls())
source("Case study 1 (survival-type endpoint).R")
rm(list = ls())
source("Case study 1 (survival-type endpoint with censoring).R")
rm(list = ls())
source("Case study 1 (count-type endpoint).R")
rm(list = ls())
source("Case study 2.R")
rm(list = ls())
source("Case study 3.R")
rm(list = ls())
source("Case study 4.R")
rm(list = ls())
source("Case study 5.R")
rm(list = ls())
source("Case study 6.R")
install.packages("C:/Users/gauti/CloudStation/Mediana Package/R/Package_v1.0.3/Mediana_1.0.3.tar.gz", repos = NULL, type = "source")
library(Mediana)
setwd("C:/Users/gauti/CloudStation/Mediana Package/R/Package_v1.0.3/Mediana-gh-pages")
rm(list = ls())
source("Case study 1 (normally distributed endpoint).R")
library(Mediana)
source("Case study 1 (normally distributed endpoint).R")
?GenerateData
GenerateData
